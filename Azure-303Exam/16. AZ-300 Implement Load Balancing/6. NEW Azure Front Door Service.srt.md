In 2019 Azure introduced a brand new service called the Azure front door service.
Now as the name kind of implies this is a technology that runs like a load balancer but at a global
scale.
And so instead of having regional load balancers and regional application gateways what we have here
is a global load balancer.
Now you might say oh it doesn't Azure traffic manager perform this well yes it kind of does but traffic
manager is a DNS hack.
It's not a real load balancer.
Front door is a real load balancer.
It also has a CDM built in so it has that network is celebration platform they're calling it.
It has a SLA.
So you Tiley available service.
So really.
And can combine apps services and virtual machines and you can put a lot of stuff behind the front door
service.
So let's start and create one so we're gonna click the create button.
Now the Frontier Service is a global service but it doesn't need to live in a resource group.
And so that resource group has a location.
I'm going to see Azure my new ARG.
I want to create a brand new resource group for this and I'm going to place the resource group in the
central U.S. location.
I'm going to go see the net configuration.
Now we do need to setup the front door service before we can create it.
And if this interface looks very familiar when it comes to setting up and load bouncer or an application
Gateway you need a front end host which is the IP configuration you need a backhand pool so that is
gonna be some services to send the traffic to and you need a set of rules to dictate how traffic it's
routing.
So let's create a front end host.
And in this case the French host is just a DNS name which is going to end in dot Azure front door dot
net.
So Scott's first front door dot Azure FTE dot net.
Now it has to be unique across all of azure.
Now do we want to force users once they go through the front door service to go to the same set of servers
every single time.
That's called session affinity or sticky sessions let's say that's disabled by default.
We're going to leave it unless you have a really good reason to force users to the same application
backend.
We also have a web application firewall.
And so if we're talking about application gateways you'll know that a firewall is an optional feature.
And so it can run the traffic that's running across the front door through a basic set of filters to
make sure that you're not being hacked just no cross site scripting or SQL Server injection etc. so
that costs money but we're going to leave that disabled so the host is pretty straightforward.
Right.
That's basically a name.
Now where are we going to send this traffic.
Now we can create what is a back pool very much similar to load bouncer now the backyard pool can be
a number of different types of things not just virtual machines but apps services as well.
So we're gonna give this a name call it back end one and we're going to basically have to add add a
server to accept the traffic.
Now what type of server we can see that we can have an app service as your app service.
It can be a storage account.
It can also be an IP address.
So if we have a a server that's running an NWS or running in our own environment that has a publicly
facing IP address then we can set that up as well.
So it works just like an application gateway in that respect.
Now for this application service I can choose my subscription I can choose from my options.
I've got a couple of WordPress options here.
Let's say that I'm gonna choose this one and Gannett can handle HP HP as traffic.
We can set priorities so we have multiple back ends one backend is a primary one back into the secondary
or are they equal priority etc..
And how are we going to distribute the traffic.
Is it 50/50 is it 90 10.
You can basically define how that gets distributed.
And of course it's enabled by default.
I can also add a second backend choose app service choose the other WordPress account now these are
different where presses but that's let's say that they're the same.
And so now I have two app services that are 50/50 going to receive traffic from Scott's first FTD or
Azure FTE dot net.
Now just like an application gateway we can set up a health probe and it's going to try and ping a sheet
AP web page and determine the status it has to come back as a successful status and we'll do that every
30 seconds and we can do that over HP as the load balancing settings will basically allow us to whether
we're going to have how many of these health events are going to have to fail in order for it's going
to be considered failed.
So if for events over 30 seconds is about two minutes if we get to successfully that means it's a healthy
backend.
So now we've added the front end we've added the backend.
Now how are we going to distribute traffic now in this case.
We only have the one back end so 100 percent of that traffic is going to go to that back end.
So the the backend rules the routing rules should be 100 percent goes to one backend.
Now if we had like a slash images or slash videos or you know we had different host headers different
domain names we could play some games here and send traffic to multiple back ends very much like our
application gateway.
So do we for the traffic or do we redirect the traffic redirecting of course is more permanent whereas
forward just this means that this is intercepting the traffic with every connection and we won't do
it.
You are I'll rewrite etc. We can turn on CBN.
So basically all static content can be can be cached and we can even turn on compression.
Like I said like like CDMA which will allow it to compress traffic.
Zip compression over HDP which will reduce the amount of bytes being sent to the end user.
And so there we have it we just set up a natural front door service.
We can add our environment equals Dev tag if we want or however
we can click review and click Create.
And if we did this then this traffic is going to basically distribute traffic 50/50 to the two WordPress
blocks that I've set up.
